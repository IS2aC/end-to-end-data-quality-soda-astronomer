# END TO END DATA QUALITY PIPELINE

# Data Architecture
![image](https://github.com/user-attachments/assets/4a9f4dc2-02e5-4a47-9bc3-f2b775f797b2)

## Details Architecture

- Google Sheets: used as the primary data source.
- Airbyte: a tool dedicated to ELT (Extract & Load) operations.
- Airflow and Astronomer: a combined solution for deploying data pipelines, integrating the open-source orchestration framework Airflow.
- Snowflake: a storage platform used to store data at each critical stage of the pipeline.
- Soda Core and Soda Cloud: solutions employed to conduct tests and monitor data quality throughout the pipeline.
- Power BI: a data visualization tool for effectively representing insights in a clear and meaningful way.

### Prerequisites:
To successfully complete this project, it’s necessary to install the following tools in advance:

<i class="fa-brands fa-docker"></i> DOCKER → Download link
ASTRO CLI → Download link
AIRBYTE CLOUD ACCOUNT (Free 14 days) → Link to Airbyte
SODA CLOUD ACCOUNT (Free 30 days) → Link to Soda
SNOWFLAKE ACCOUNT → Link to Snowflake
And of course, Python 3.X because the code won’t writ


